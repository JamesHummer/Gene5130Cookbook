---
title: "Bioinformatics in R WGCNA"
author: "J. Cesar Ignacio Espinoza - Cesar   "
date: "Week 05: April 21th and 23rd 2025"
output: 
  html_document: 
    highlight: espresso
    theme: cerulean
editor_options: 
  markdown: 
    wrap: 72
---

### This class will incorporate a bit of ML.

We will be performing a WGNCA, before proceeding test yourself and make
sure you understand what weighted. Gene_network and correlation mean?

## The dataset.

we will be working with the dataset " Systems biological assessment of
immunity to severe and mild COVID-19 infections"

RNAseq analysis of PBMCs in a group of 17 COVID-19 subjects and 17
healthy controls "
```{r}

```

```{r setup}
    ### Edit this line so your notebook renders properly
    knitr::opts_knit$set(root.dir = normalizePath("C:/Users/james/OneDrive/Desktop/MSGDA/Bioinformatics in R")) 
```

We will be using the package called WGCNA, if you do not have it
install, please run this cell, once it is installed comment it!

```{r}
#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")
#BiocManager::install("GO.db")
#BiocManager::install("WGCNA")
#version
```

```{r setup}
BiocManager::install(c("WGCNA", "GO.db", "impute", "preprocessCore"), dependencies = TRUE)
```


We now load the libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE, results="hide"}
# We first need to import the important libnrary for today's class, dplyr
library(WGCNA)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
```

Load the data (Counts table and metadata from canvas site)

```{r}
### Run this chunk to import the counts table and metadata into your evironment.
counts <- read.csv('GSE152418RawCounts.csv', header = TRUE, row.names = 1)
metadata <- read.csv('GSE152418Metadata.csv', header = TRUE, row.names = 1)

```

### QC:

Here we wanna explore to see if the dataset that we have is good for
analysis We are going to use a function called goodSamplesGenes(). Use
the cell below to display the help page of this function, figure out if
you can run it, look at the vignette and identify what this function is
doing.

```{r}
#?goodSamplesGenes()

```

```{r}
### It look at the boolean list, and use it to subset your dataset
```

Subset your data so only the genes that passed the filter are kept

```{r}
#base r
counts_transposed = t(counts) 
counts_really_transposed = transposeBigData(counts)
good <- goodSamplesGenes(counts_really_transposed, weights = NULL,
  minFraction = 1/2, 
  tol = NULL,
  minRelativeWeight = 0.1,
  verbose = 1, indent = 0)

### dplyr

```

```{r}
counts_filtered <- counts_really_transposed[good$goodGenes, ]

```
#### Quick lecture 5 mins

#Sidequest 20 mins:

```{r}
# Run this cell as it is, it is generatig artificial data 
set.seed(123)
group1 <- matrix(rnorm(40, mean = 0), ncol = 2)
group2 <- matrix(rnorm(40, mean = 2.5), ncol = 2)
group3 <- matrix(rnorm(40, mean = 8), ncol = 2)

#sends to dataframe
data <- rbind(group1, group2, group3)
rownames(data) <- paste0("P", 1:nrow(data))

# Plot 
df <- as.data.frame(data)
colnames(df) <- c("x", "y")
ggplot(df, aes(x, y)) + 
  geom_point() + 
  theme_minimal()
```

Lookup the hclust function and perform clustering the data, try
different distance methods and agglomeration methods.

```{r}
### Try different distances and methods
```

```{r}
d <- dist(df, method = "euclidean", diag = FALSE, upper = FALSE, p = 2)
x <- hclust(d, method = "ward.D", members = NULL)
plot(x, labels = NULL, hang = 0.1, check = TRUE,
     axes = TRUE, frame.plot = FALSE, ann = TRUE,
     main = "Cluster Dendrogram",
     sub = NULL, xlab = NULL, ylab = "Height")
```

```{r}
d <- dist(df, method = "manhattan", diag = FALSE, upper = FALSE, p = 2)
x <- hclust(d, method = "complete", members = NULL)
plot(x, labels = NULL, hang = 0.1, check = TRUE,
     axes = TRUE, frame.plot = FALSE, ann = TRUE,
     main = "Cluster Dendrogram",
     sub = NULL, xlab = NULL, ylab = "Height")
```

```{r}
d <- dist(df, method = "maximum", diag = FALSE, upper = FALSE, p = 2)
x <- hclust(d, method = "single", members = NULL)
plot(x, labels = NULL, hang = 0.1, check = TRUE,
     axes = TRUE, frame.plot = FALSE, ann = TRUE,
     main = "Cluster Dendrogram",
     sub = NULL, xlab = NULL, ylab = "Height")
```

```{r}
d <- dist(df, method = "canberra", diag = FALSE, upper = FALSE, p = 2)
x <- hclust(d, method = "average", members = NULL)
plot(x, labels = NULL, hang = 0.1, check = TRUE,
     axes = TRUE, frame.plot = FALSE, ann = TRUE,
     main = "Cluster Dendrogram",
     sub = NULL, xlab = NULL, ylab = "Height")
```
How do the shapes of the deprograms differ?

Which method best recovers the intuitive groupings from the 2D plot?

When might you prefer a chaining method like "single" vs. compact (the
algorithm reduces the variance within created cluster) like "ward.D2"?

```{r}
#### Run this cell as it just plots your points beased on the create clusters
cut_and_color <- function(method, k = 3) {
  hc <- hclust(d, method = method)
  clusters <- cutree(hc, k = k)
  df$cluster <- as.factor(clusters)
  ggplot(df, aes(x, y, color = cluster)) + 
    geom_point(size = 3) +
    labs(title = paste("Clusters with", method, "linkage")) +
    theme_minimal()
}
```

```{r}
### Run our custom fucntion here, try different agglomaeration methods, and distance
```

#Discuss:

How could this apply to real biological data (e.g., gene expression
clustering)?

## Back to our main topic

Perform clustering on our data **HINT!!!** Double check that columns and
rows are as the program expects them!

A good way to detect outliers is to perform hierarchical clustering of
all the samples. If you do that you should be able to see if some data
points are too far from the rest of the samples.

```{r}
#### Perform CLustering, plot it! WHich samples would you remove?
### Int you can use the base R plot function on the object resulting from clustering
d2 <- dist(counts_really_transposed, method = "canberra", diag = FALSE, upper = FALSE, p = 2)
x2 <- hclust(d2, method = "average", members = NULL)
plot(x2, labels = NULL, hang = 0.1, check = TRUE,
     axes = TRUE, frame.plot = FALSE, ann = TRUE,
     main = "Cluster Dendrogram",
     sub = NULL, xlab = NULL, ylab = "Height")

```

```{r}
### Write your code here
pr <- prcomp(counts_really_transposed)

ggplot(data = pr$x, aes(x = PC1, y = PC2)) + geom_point() + geom_label(aes(label = rownames(pr$x)))
```

Outliers are literally that samples taht are far from each other, we can
also look at that by applying dimensionality reduction, one of the most
common techniques is PCA. run the cell below to go to the help page for
PCA

```{r}
#?prcomp
```

```{r}
#### REMOVE THIS 
new_counts <- counts %>% select(-'GSM4615000', -'GSM4614995', -'GSM4614993', -'GSM4614985')
```


# Filter the data to remove bad samples

**HINT** Use DPlyr

```{r}
### TO BE REMOVED

```

#Normalization.

The 'easiest' way will be to run DESEq2 and use the normalized counts
object from DESeq2, Look at your past notes and run it below. You have
all you need but you might need to play with the metadata file. HINT :
df[!(row.names(df) %in% row_names_df_to_remove),] \###

```{r}

### WRITE YOUR CODE HERE, ALSO RENAME THE COLUMNS OF METADATA SO IT IS EASIER TO READ, REMOVE 'DOTS' 
tmetadata <- as.data.frame(t(metadata))
new_metadata <- tmetadata %>% select(-'GSM4615000', -'GSM4614995', -'GSM4614993', -'GSM4614985')
final_metadata <- as.data.frame(t(new_metadata)) %>% select(-geo_accession, -geographical.location.ch1) %>%
  dplyr::rename('gender' = 'gender.ch1') %>%
  dplyr::rename('severity' = 'severity.ch1') %>%
  dplyr::rename('state' = 'disease.state.ch1', 'days' = 'days_post_symptom_onset.ch1')
```

```{r}
#new_pheno <-  ### rename headers, done above
```
```{r}
#.rs.restartR()
```


```{r}
all(rownames(final_metadata) %in% colnames(new_counts))
class(new_counts)        # should be 'data.frame' or 'matrix'
class(final_metadata)    # should be 'data.frame'
str(final_metadata$state)  # should be 'Factor'
```

```{r}
# Check if SummarizedExperiment is installed and up-to-date
#if (!requireNamespace("SummarizedExperiment", quietly = TRUE)) {
#    BiocManager::install("SummarizedExperiment")
#} else {
#    packageVersion("SummarizedExperiment")
}
```
```{r}
# Reinstall core Bioconductor packages
#BiocManager::install(c("S4Vectors", "SummarizedExperiment", "GenomicRanges"), force = TRUE)

```
```{r}
#remove.packages("DESeq2", lib = "C:/Users/james/AppData/Local/R/win-library/4.5")
#BiocManager::install("DESeq2", lib = "C:/Users/james/AppData/Local/R/win-library/4.5")
```

```{r}
### RunDeseq2
#if (!requireNamespace("BiocManager", quietly = TRUE))
# install.packages("BiocManager")

#BiocManager::install("DESeq2")
#install.packages("SummariedExperiment")
#setClassUnion("ExpData", c("matrix", "SummarizedExperiment"))
#library(DESeq2)
#dds <- DESeqDataSetFromMatrix()
final_metadata$state <- as.factor(final_metadata$state)
#create a deseqobject

#new_counts <- as.data.frame(new_counts)
#final_metadata <- as.data.frame(final_metadata)

dds <- DESeqDataSetFromMatrix(countData = new_counts,
                              colData = final_metadata,
                              design = ~ state)
## Subset your deseq objecta
dds75 <-  dds[(rowSums(counts(dds)) >= 23)]

### fix the base to a preferred column/result
relevel(dds75$state, ref='Healthy')

### Run deseq2

deseq_ob <- DESeq(dds75)

#### Save the results to a new object
res <- results(deseq_ob, alpha = 0.05)
```
```{r}
#?DESeq2
```

Now remove the genes with counts \< 15 in more than 75% of samples
(31\*0.75 \~ 23) This number is coming from the WGCNA recommendations

```{r}
#all done in one chunk above
dds75 <- dds[(rowSums(counts(dds)) >= 23),]### Subset
```

```{r}
#skipped
dds_norm <- vst(dds75)    ### This applies the normalization without running the whole DESEQ2 function
norm_gene_exp <- assay(dds_norm) %>% t() ### WGCNA needs the data in a particular shape, make sure this matches it

```

```{r}
res
```

### Before proceeding with WGCNA, let's see if you are keeping a cookbook with R, make a vol cano plot, and a heatmap with the DSEQ data you just generated.

```{r}
#ran in one chunk above
#deseq_ob <- DESeq(dds75)

#### Save the results to a new object
#res <- results(deseq_ob, alpha = 0.05)

```

```{r}
### Print a volcano
# Add a column to mark significance
res$threshold <- as.factor(res$padj < 0.05 & abs(res$log2FoldChange) > 1)

# Plot
ggplot(res, aes(x=log2FoldChange, y=-log10(padj), color=threshold)) +
  geom_point(alpha=0.6, size=1.5) +
  scale_color_manual(values=c("grey", "red")) +
  theme_minimal() +
  labs(title="Volcano Plot", x="log2 Fold Change", y="-log10 Adjusted P-value") +
  theme(legend.title=element_blank())
```

```{r}
### Subset for a heatmap
vsd <- vst(dds75, blind=FALSE) 
# Subset by adjusted p-value and log2FC
sig_genes <- res[which(res$padj < 0.05 & abs(res$log2FoldChange) > 1), ]
# Keep top 30 genes by significance (optional)
top_genes <- head(rownames(sig_genes[order(sig_genes$padj), ]), 30)
mat <- assay(vsd)[top_genes, ]  # matrix of transformed counts
mat <- mat - rowMeans(mat)      # optional: center the rows

```

```{r}
### Print your heatmap
library(pheatmap)
pheatmap(mat, 
         cluster_rows=TRUE, 
         cluster_cols=TRUE, 
         show_rownames=TRUE, 
         scale="row", 
         fontsize=10,)
```

# We can finally start with our WGNCA data analysis

First we pick up a soft threshold modify the power vector below

```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:20), 
                  networkType = "signed", 
                  verbose = 2)
```

You can acess the results with sft\$fitIndices. We are going to pick a
power that gives us the higherst R2 and the lowest mean K.

**HINT plot the data!** First plot Power vs r2

```{r}
ggplot(data = sft$fitIndices, aes(x = Power, y = SFT.R.sq)) + geom_point()
```

Then Plot Power vs mean.k

```{r}
### Follow the example above and plot meanK 
ggplot(sft$fitIndices, aes(x = Power, y = mean.k., color = "seagreen")) +
  geom_point()
```

After you pick up a threshold we are ready to run our data analysis

While it runs take a look at the vignette
(<https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules>)
to learn about the parameters

```{r}
### Uncoment these cells if you get issues
temp_cor <-  cor
cor <- WGCNA::cor

norm_gene_exp[] <- sapply(norm_gene_exp, as.numeric)
### This is the mean meat and potatos function
bwm <- blockwiseModules(norm_gene_exp, 
                 maxBlockSize = 40000,
                 TOMType = "signed",
                 power = 7, 
                 mergeCutHeight = 0.2, 
                 numericLabels = FALSE, 
                 randomSeed = 1234, 
                 verbose = 2)

```

[\#](https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules)explore
the bwm object, how many modules are there? What us the largest module?
What is the smallest?

```{r}
## RUN THIS AS IS, IT WILL PLOT THE COLORS AND DENDROGRAM
## https://www.rdocumentation.org/packages/WGCNA/versions/1.72-5/topics/plotDendroAndColors
mergedColors = labels2colors(bwm$colors)
plotDendroAndColors(
  bwm$dendrograms[[1]],
  mergedColors[bwm$blockGenes[[1]]],
  "Module colors",
  dendroLabels = FALSE,
  hang = 0.03,
  addGuide = TRUE,
  guideHang = 0.05)
```

# Now we can correlate our findings with phenotype states of patients

Take a look at the phenotype table, we want to correlate these with our
modules (groups of genes), "one-hot encoding", for example"

```         
labels <- c("A", "B", "C")

# One-hot:
A = [1 0 0]
B = [0 1 0]
C = [0 0 1]
```

```{r}
### The easiest way is just to add a new column and subset it at the end, look at the example below, work your way and modify all the relevant traits
traits <- final_metadata %>%
  mutate(disease_state_bin = ifelse(grepl('COVID', disease.state.ch1),1,0)) %>%
  mutate(moderate_bin = ifelse(grepl('Moderate', severity.ch1), 1,0)) %>%
  mutate(moderate_bin = ifelse(grepl('ICU', severity.ch1), 1,0)) %>%
  mutate(healthy_bin = ifelse(grepl('Health', severity.ch1), 1,0)) %>%
  mutate(gender_bin = ifelse(grepl('M', gender.ch1), 1,0)) %>%
  dplyr::select(8:11)
  

traits <- traits[-1, ]
traits
```

```{r}
traits <- new_pheno %>%

```

```{r}
correlations = cor()
```

```{r}
pvalues = corPvalueStudent()
```

```{r}
## Visualiza our moduels as a heatmap
library(ComplexHeatmap)
Heatmap(correlations)
```

Pick up a few modules of interest

```{r}
## Extract the genenames of a module of interest run GSEA on it. 
### HINTS: 
labels2colors(bwm$colors)
names(bwm$colors)

### The easiest ways is to load thes two into  a DF and subset from there, but you can do it anyway.
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```
